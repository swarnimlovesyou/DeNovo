#!/usr/bin/env python3
"""
Model Packaging Script for ADMET Prediction

This script packages a trained model for sharing/distribution.
Creates a self-contained model package with all necessary files.

Usage:
    python package_model.py --model_dir path/to/model/checkpoints --output model_package.zip

Author: ADMET Pipeline
"""

import os
import zipfile
import argparse
import yaml
import torch
from pathlib import Path
from datetime import datetime

def load_config(config_path):
    """Load configuration from YAML file"""
    with open(config_path, 'r') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    return config

def create_model_package(model_dir, output_path, task_name):
    """Create a self-contained model package"""

    model_dir = Path(model_dir)
    output_path = Path(output_path)

    if not model_dir.exists():
        raise FileNotFoundError(f"Model directory not found: {model_dir}")

    if not (model_dir / 'model.pth').exists():
        raise FileNotFoundError(f"Model weights not found: {model_dir / 'model.pth'}")

    if not (model_dir / 'config_finetune.yaml').exists():
        raise FileNotFoundError(f"Config file not found: {model_dir / 'config_finetune.yaml'}")

    print(f"üì¶ Creating model package for {task_name}")

    # Create package directory
    package_dir = output_path.parent / f"{output_path.stem}_package"
    package_dir.mkdir(exist_ok=True)

    # Copy model files
    model_files = [
        'model.pth',
        'config_finetune.yaml'
    ]

    for file in model_files:
        src = model_dir / file
        dst = package_dir / file
        if src.exists():
            import shutil
            shutil.copy2(src, dst)
            print(f"‚úì Copied {file}")

    # Create model info file
    config = load_config(model_dir / 'config_finetune.yaml')

    # Determine task type from task_name
    task_name_lower = config['task_name'].lower()
    if task_name_lower in ['bbbp', 'bace', 'clintox', 'tox21', 'hiv', 'sider', 'muv']:
        task_type = 'classification'
    elif task_name_lower in ['freesolv', 'esol', 'lipo', 'qm7', 'qm8', 'qm9', 'caco2', 'clearance', 'hlm_clint']:
        task_type = 'regression'
    else:
        task_type = 'unknown'

    # Load model to get architecture info
    device = torch.device('cpu')
    if config['model_type'] == 'gin':
        from models.ginet_finetune import GINet
        model = GINet(task_type, num_tasks=config['num_tasks'], **config["model"])
    elif config['model_type'] == 'gcn':
        from models.gcn_finetune import GCN
        model = GCN(task_type, num_tasks=config['num_tasks'], **config["model"])
    else:
        raise ValueError(f"Unknown model type: {config['model_type']}")

    # Load state dict to get parameter count
    state_dict = torch.load(model_dir / 'model.pth', map_location=device)
    model.load_state_dict(state_dict)

    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    # Create README
    readme_content = f"""# ADMET Prediction Model Package

## Model Information
- **Task**: {task_name}
- **Model Type**: {config['model_type'].upper()}
- **Task Type**: {task_type}
- **Number of Tasks**: {config['num_tasks']}
- **Total Parameters**: {total_params:,}
- **Trainable Parameters**: {trainable_params:,}

## Usage

### Requirements
```
torch>=2.0.0
torch-geometric>=2.0.0
rdkit>=2020.09.1
pyyaml>=5.4.1
scikit-learn>=1.0.0
pandas>=1.3.0
```

### Quick Start
```python
import torch
from models.{config['model_type']}et_finetune import {'GINet' if config['model_type'] == 'gin' else 'GCN'}
import yaml

# Load config
with open('config_finetune.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Create model
model = {'GINet' if config['model_type'] == 'gin' else 'GCN'}(
    config['dataset']['task'],
    num_tasks=config['num_tasks'],
    **config["model"]
)

# Load weights
model.load_state_dict(torch.load('model.pth', map_location='cpu'))
model.eval()

# Now you can use the model for inference!
```

### Using the Inference Script
```bash
python inference.py --model_path model.pth --data_path your_data.csv --task_name {task_name} --config config_finetune.yaml
```

## Files Included
- `model.pth`: Trained model weights
- `config_finetune.yaml`: Model configuration
- `README.md`: This documentation

## License
See main repository LICENSE file.

---
Generated by ADMET Pipeline
"""

    with open(package_dir / 'README.md', 'w') as f:
        f.write(readme_content)

    print("‚úì Created README.md")

    # Create ZIP archive
    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file in package_dir.glob('*'):
            zipf.write(file, file.name)

    print(f"‚úì Created package: {output_path}")

    # Clean up
    import shutil
    shutil.rmtree(package_dir)

    print("\nüéâ Model package created successfully!")
    print(f"   Location: {output_path}")
    print(f"   Size: {output_path.stat().st_size / 1024:.1f} KB")

    return output_path

def main():
    parser = argparse.ArgumentParser(description='Package ADMET Model for Distribution')
    parser.add_argument('--model_dir', type=str, required=True,
                       help='Path to model checkpoints directory')
    parser.add_argument('--output', type=str, default='model_package.zip',
                       help='Output ZIP file path')
    parser.add_argument('--task_name', type=str, required=True,
                       help='ADMET task name (BBBP, caco2, etc.)')

    args = parser.parse_args()

    # Create packages folder structure
    packages_base_dir = 'packages'
    os.makedirs(packages_base_dir, exist_ok=True)

    # Create timestamped subfolder for this package
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    task_name = args.task_name.lower()
    package_dir = os.path.join(packages_base_dir, f'{task_name}_{timestamp}')
    os.makedirs(package_dir, exist_ok=True)

    # Update output path to use the packages folder
    if args.output == 'model_package.zip':  # default value
        args.output = os.path.join(package_dir, f'{task_name}_model_package.zip')
    else:
        # If custom output path provided, place it in packages folder
        args.output = os.path.join(package_dir, os.path.basename(args.output))

    print(f"üìÅ Package will be saved to: {package_dir}")

    try:
        create_model_package(args.model_dir, args.output, args.task_name)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())